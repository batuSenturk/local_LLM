# local_LLM
A local LLM using NVIDIA's Llama
